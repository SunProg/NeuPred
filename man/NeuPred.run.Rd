% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NeuPred.R
\name{NeuPred.run}
\alias{NeuPred.run}
\title{Main function}
\usage{
NeuPred.run(summs, LDpath = NULL, LDpath.chr = NULL, n,
  external.ld = T, ethnic = "EUR", plinkpath, path, prior = "auto",
  testpath = NULL, MCMC = 10000, BURN = 2000, parallel = T,
  cores = 5, chr = 1:22, plot = F, scale = T, tmp = T,
  shrink.comp = F)
}
\arguments{
\item{summs}{GWAS summary statistics, must include}

\item{LDpath}{The path to reference LD files.  The LDpath should include the file name (without .bim/.fam/.bed)}

\item{LDpath.chr}{The path to the reference LD files (by chromosome). The LDpath_chr should include the file name but not the exact number of chromosome (e.g., LDpath_chr='path/1000G.EUR.QC.').}

\item{n}{GWAS sample size.}

\item{external.ld}{T/F. Whether the LD matrix is estimated from a external reference panel (e.g., 1000G). We suggest external.ld=T when the sample size of the LD reference is less than 1000. Default=T.}

\item{ethnic}{'EUR'/'AFR'/'ASN', The ethnic of GWAS summary statistics.}

\item{plinkpath}{The full path to plink software.}

\item{path}{The full path to save the result files.}

\item{prior}{'auto'/'L'/'C'/'HS'. If not specified, when external.ld=T, the prior would be set to 'L'; when external.ld=F, meaning that the LD is accurately estimated, the prior would be set to 'auto', and the algorithm will use a CV strategy to automatically select the best-performing prior for each chromosome using only training data (details are provided in the paper).}

\item{testpath}{The full path to tht test data. If the test data is provided, the algorithm will calculate the overlapped SNPs between test data and training data, and then present the predictive r^2 and AUC (for binary traits), and give a ROC plot. If the test data is not provided, the algorithm will derive the posterior effect sizes for all SNPs in training dataset.}

\item{MCMC}{MCMC iteration times. Default=10000.}

\item{BURN}{MCMC burning times. Default=2000.}

\item{parallel}{T/F.  To decide whether to run the algorithm in parallel to speed up, default=T. Note that parallel=T will improve the computational effiency, but pay attention to the limits of memory.}

\item{cores}{Number of cores for running MCMC when parallel=T, the optional is min(5, # available cores).}

\item{chr}{Default=1:22.}

\item{plot}{Default=F. Provide an AUC plot for binary traits.}

\item{scale}{Default=T. If the effect sizes are used for standardized genotypes, please set scale=T; if the effect sizes are used for raw genotypes (0,1,2), such as calculating scores with PLINK, please set scale=F}

\item{tmp}{Default=T.  If tmp=T, the temp files will be kept, including the LD blocks, test files, etc. If tmp=F, the temp files will be deleted after the results have been generated.}

\item{shrink.comp}{Default=F.  compulsorily shrink the LD matrix.}
}
\value{
a list containing:
$res: The predictive r2 and AUC with selected prior.
$res.all: The predictive r2 and AUC with all three priors including Neuronized SpSL-Laplace prior, Neuronized SpSL-Cauchy prior, and Neuronized Horseshoe prior.
$select.prior: The prior automatically selected.
$S: estimated polygenic risk score.
}
\description{
A unified Bayesian framework to calculate PRS based on GWAS summary statistics
}
\references{
Song, S.,  Hou, L. and Jun, S.L. A data-adaptive Bayesian regression approach  for accurate polygenic risk prediction. \emph{Submitted}.
}
